# Copyright 2024 - 2025 Block, Inc.
#
# Use of this source code is governed by an MIT-style
# license that can be found in the LICENSE file or at
# https://opensource.org/licenses/MIT.
#
# frozen_string_literal: true

# Note: we need to avoid loading anything here except rake and standard library things, because
# our release workflow loads this with a minimal Gemfile that lacks most of our dependencies.
require "yaml"
require "pathname"
require "rake/tasklib"

module ElasticGraph
  class SiteRakeTasks < ::Rake::TaskLib
    SITE_CONFIG_DIR = ::Pathname.new(__dir__)
    REPO_ROOT = SITE_CONFIG_DIR.parent.parent
    SITE_SOURCE_DIR = SITE_CONFIG_DIR / "src"
    API_DOCS_DIR = SITE_SOURCE_DIR / "api-docs"
    ARCHIVED_API_DOCS_DIR = SITE_CONFIG_DIR / "archived_docs"
    YARD_OUTPUT_DIR = API_DOCS_DIR / "main"
    JEKYLL_SITE_DIR = SITE_CONFIG_DIR / "_site"
    JEKYLL_API_DOCS_DIR = JEKYLL_SITE_DIR / "api-docs"
    JEKYLL_DATA_DIR = SITE_SOURCE_DIR / "_data"
    EXAMPLE_SCHEMA_FILES_BY_NAME = SITE_CONFIG_DIR.glob("examples/*/schema.rb").to_h do |file|
      [file.parent.basename.to_s, file]
    end

    # The list of currently undocumented gems. Over time we're going to shrink this until it's empty.
    undocumented_gems = %w[
      elasticgraph
      elasticgraph-admin
      elasticgraph-datastore_core
      elasticgraph-graphql
      elasticgraph-health_check
      elasticgraph-indexer
      elasticgraph-lambda_support
      elasticgraph-query_interceptor
      elasticgraph-query_registry
    ]

    require_relative "../../script/list_eg_gems"
    DOCUMENTED_GEMS = ::ElasticGraphGems.list - undocumented_gems

    def initialize
      namespace :site do
        task build_docs: [:unpack_doc_archives] do
          # Clean the docs output directory
          FileUtils.rm_rf(YARD_OUTPUT_DIR)
          run_yard_doc_ignoring_expected_warnings
        end

        # Note: we tried to get this setup as a single task that serves load for all ElasticGraph gems,
        # but we haven't succeeded in getting that to work. We've only gotten it to work by changing
        # to a specific gem directory to run the command.
        namespace :preview_docs do
          ::ElasticGraphGems.list.each do |gem|
            desc "Boots a reloading doc server for `#{gem}`."
            task gem do
              ::Dir.chdir(gem) do
                sh "bundle exec yard server --reload"
              end
            end
          end
        end

        desc "Check documentation coverage"
        task :docs_coverage do
          doc_output = run_yard_doc_ignoring_expected_warnings

          coverage = doc_output[/([\d\.]+)% documented/, 1]
          warning_count = doc_output.scan("[warn]:").count
          error_count = doc_output.scan("[error]:").count

          if coverage.to_f < 100
            # Since we do not have 100% coverage, we want to list what is undocumented.
            #
            # Note: we don't use this as the main command above because we've observed that
            # `stats` does not produce as many warnings as `doc`--so we'd rather run `doc`
            # when detecting warnings, and use `stats --list-undoc` for supplemental output.
            undoc_output = IO.popen(yard_cmd("stats --list-undoc")).read

            # Just print the output starting with `Undocumented Objects"
            puts "\n#{undoc_output[/^Undocumented .*/m]}"
          end

          issues = []
          issues << "Missing documentation coverage (currently at #{coverage}%)." if coverage.to_f < 100
          issues << "YARD emitted #{warning_count} documentation warning(s)." if warning_count > 0
          issues << "YARD emitted #{error_count} documentation error(s)." if error_count > 0

          unless issues.empty?
            abort <<~EOS

              Documentation has #{issues.size} issues:

              #{issues.map { |i| " - #{i}" }.join("\n")}
            EOS
          end
        end

        desc "Tests all documentation examples."
        task :doctest do
          require "yard-doctest"

          # Change the log level to ERROR in order to silence yard warnings.
          # (We deal with yard warnings in `docs_coverage` and don't want to also print them here.)
          ::YARD::Logger.instance.enter_level(::Logger::ERROR) do
            # We change into this directory because `yard-doctest` loads `doctest_helper.rb` from specific paths
            # such as `support/doctest_helper.rb`.
            ::Dir.chdir(__dir__) do
              paths_with_yard_examples = ::ElasticGraphGems.list.map do |gem|
                "#{REPO_ROOT}/#{gem}/lib"
              end

              ::YARD::CLI::Doctest.run(*paths_with_yard_examples)
            end
          end
        end

        task :npm_install do
          ::Dir.chdir(SITE_CONFIG_DIR) do
            sh "npm install"
          end
        end

        desc "Build Jekyll site with freshly generated YARD documentation"
        task build: [:build_docs, :build_css, "examples:extract_snippets", :extract_content] do
          run_jekyll :build
        end

        desc "Extract searchable and LLM-friendly content"
        task extract_content: [:build_docs] do
          require_relative "support/content_extractor"

          # Build Jekyll content so that we have parsable HTML to extract content from
          run_jekyll :build

          extractor = ContentExtractor.new(
            jekyll_site_dir: JEKYLL_SITE_DIR,
            api_docs_dir: API_DOCS_DIR
          )

          content = extractor.extract_content
          output_file = JEKYLL_DATA_DIR / "content.yaml"

          puts "Writing content to #{output_file}:"
          puts " - #{content["searchable_content"].size} searchable pages"
          puts " - LLM content: #{(content["llm_content"]["size"] / 1024.0).round(1)}KB"

          # Write to data file
          ::FileUtils.mkdir_p(JEKYLL_DATA_DIR)
          ::File.write(output_file, ::YAML.dump(content))
        end

        desc "Build YARD docs and create versioned archive"
        task :archive_docs, [:version] => [:build_docs] do |_, args|
          abort "Version argument is required (e.g., rake site:archive_docs[1.0.0])" unless args[:version]

          archive_name = "v#{args[:version]}.tar.gz"
          archive_path = ARCHIVED_API_DOCS_DIR / archive_name

          FileUtils.mkdir_p(ARCHIVED_API_DOCS_DIR)

          Dir.chdir(YARD_OUTPUT_DIR) do
            # --no-xattrs is necessary to ensure that apple-specific attributes are excluded from the archive.
            # When unpacking the archives on linux system, it produces warnings if we allow apple's extended
            # attributes to be included.
            sh "tar --no-xattrs -czf #{archive_path} ."
          end

          puts "Documentation archive created at: #{archive_path}"
        end

        desc "Unpack all documentation archives into src/api-docs"
        task :unpack_doc_archives do
          # Clean the docs directory
          FileUtils.rm_rf(API_DOCS_DIR)

          Dir.glob(ARCHIVED_API_DOCS_DIR / "*.tar.gz").sort.each do |archive|
            version_name = File.basename(archive, ".tar.gz")
            target_dir = API_DOCS_DIR / version_name

            # Remove existing directory if it exists
            FileUtils.rm_rf(target_dir)
            FileUtils.mkdir_p(target_dir)

            puts "Unpacking #{version_name} documentation..."
            Dir.chdir(target_dir) do
              sh "tar -xzf #{archive}"
            end
          end

          puts "All documentation archives have been unpacked"
        end

        desc "Serve Jekyll site locally"
        task serve: [:build_docs, :build_css, "examples:extract_snippets", :extract_content] do
          require "filewatcher"

          # Regenerate the YARD docs anytime we change anything in the source code of the gems that are documented.
          watch_files(
            "Regenerating YARD docs",
            DOCUMENTED_GEMS.map { |g| "#{g}/" }
          ) do
            run_yard_doc_ignoring_expected_warnings
          end

          # Recompile queries when any of the examples change.
          watch_files(
            "Recompiling GraphQL queries into data files",
            EXAMPLE_SCHEMA_FILES_BY_NAME.values.map { |f| "#{f.parent}/" },
            exclude: "**/*.variables.yaml"
          ) do |changed_files|
            changed_files.each do |file|
              t1 = ::Time.now
              example_schema = file.to_s.split("/")[3]
              task = ::Rake::Task["site:examples:#{example_schema}:extract_snippets"]
              task.all_prerequisite_tasks.each(&:reenable)
              task.tap(&:reenable).invoke
              t2 = ::Time.now

              puts "Done in #{(t2 - t1).round(3)} seconds."
            rescue => e
              # Print validation errors and allow the filewatcher to continue.
              puts <<~EOS
                #{e.class}: #{e.message}

                #{e.backtrace.join("\n")}
              EOS
            end
          end

          ::Thread.new do
            ::Dir.chdir(SITE_SOURCE_DIR) do
              sh "npm run serve:css"
            end
          end

          run_jekyll :serve
        end

        desc "Validate the site's HTML output"
        task :validate_html_output do
          require "html-proofer"

          # Helper lambda to run HTMLProofer with retries
          run_html_proofer = lambda do |directory, max_retries: 3, **options|
            attempt = 0
            begin
              attempt += 1
              puts "Checking #{directory} (attempt #{attempt}/#{max_retries})" if attempt > 1
              HTMLProofer.check_directory(directory.to_s, **options).run
            rescue ::Exception => e # standard:disable Lint/RescueException -- rescuing `StandardError` doesn't work here.
              if attempt < max_retries
                puts "Error checking #{directory}, retrying in 2 seconds..."
                sleep 2
                retry
              else
                raise e
              end
            end
          end

          # Use strict settings when checking everything except our YARD docs.
          run_html_proofer.call(
            JEKYLL_SITE_DIR,
            # We are not in control of the generated YARD docs, and need to check them with more relaxed settings.
            ignore_files: [%r{#{JEKYLL_API_DOCS_DIR}/.+/}o],
            # Needed so our internal URLs are resolved correctly.
            swap_urls: {%r{^/elasticgraph/} => "/"},
            # Our "Getting Started" page links to the locally booted ElasticGraph, which HTMLProofer can't resolve.
            ignore_urls: ["http://localhost:9000/"]
          )

          # Use more relaxed settings when checking the HTML documentation pages generated by YARD for released versions.
          # We treat the YARD docs for previously released versions as being immutable, and have no plans to fix issues
          # like broken external links, etc.
          run_html_proofer.call(
            JEKYLL_API_DOCS_DIR,
            ignore_files: [/#{JEKYLL_API_DOCS_DIR / "main"}/o, "#{JEKYLL_API_DOCS_DIR}/index.html"],
            ignore_urls: ["elasticgraph-rack/lib/elastic_graph/rack/graphiql/index.html"],
            check_external_hash: false,
            ignore_missing_alt: true,
            allow_missing_href: true,
            disable_external: true
          )

          # We use stricter settings for the newly generated YARD docs, since we can actually fix these.
          run_html_proofer.call(
            JEKYLL_API_DOCS_DIR / "main",
            # YARD generates a bunch of anchor tags with no hrefs, which we can't do anything about.
            allow_missing_href: true
          )
        end

        desc "Validate that no code snippets are empty"
        task :validate_no_empty_code_snippets do
          require_relative "support/validate_no_empty_code_snippets"
          ElasticGraph::ValidateNoEmptyCodeSnippets.new(JEKYLL_SITE_DIR).validate!
        end

        desc "Validate that all pages have proper frontmatter with permalink"
        task :validate_page_frontmatter do
          require "yaml"

          # Find all markdown and HTML files in src directory
          src_dir = SITE_SOURCE_DIR
          pages = Dir.glob("#{src_dir}/**/*").reject do |file|
            # Skip directories, files in directories that don't contain pages, binary files, and specific file types
            File.directory?(file) ||
              %w[/_data/ /api-docs/ /_includes/ /_layouts/ /_plugins/ /_config.yaml dc.yml /examples/ /assets/].any? { |dir| file.include?(dir) } ||
              %w[.js .css .png .jpg .jpeg .gif .ico .svg .woff .woff2 .ttf .eot .webmanifest .yaml .graphql].include?(File.extname(file).downcase) ||
              file.end_with?(".graphql.txt")
          end

          # Check each page to make sure the frontmatter specifies a `permalink`. This matters because it ensures consistent behavior
          # when serving the site locally (e.g. for development) and on GitHub pages. We've discovered that when serving the site locally
          # through jekyll, the server is more "forgiving" than GitHub pages. For example, the local server served `search.html` from
          # `/search/` and `/search`, but on GitHub pages it only served from `/search`.Requiring a permalink set on each page forces us
          # to explicitly pick what URL the page is served from, and will help ensure consistent behavior between local development and
          # GitHub pages.
          failed_pages = pages.filter_map do |page|
            relative_path = Pathname.new(page).relative_path_from(src_dir)
            begin
              content = File.read(page, encoding: "utf-8")

              # Check if file has frontmatter (content between --- markers)
              if content =~ /\A---\s*\n(.*?)\n---\s*\n/m
                frontmatter = YAML.safe_load($1)

                if !frontmatter.key?("permalink")
                  [relative_path, "Missing permalink in frontmatter"]
                elsif frontmatter["permalink"].nil?
                  [relative_path, "Permalink is null"]
                elsif frontmatter["permalink"].strip.empty?
                  [relative_path, "Permalink is empty"]
                end
              else
                [relative_path, "No frontmatter found"]
              end
            rescue Encoding::InvalidByteSequenceError => e
              puts "Warning: Encoding issue in file #{relative_path}: #{e.message}"
              next  # Skip files with encoding issues
            rescue => e
              puts "Error processing file #{relative_path}: #{e.message}"
              raise e
            end
          end

          unless failed_pages.empty?
            abort <<~MESSAGE
              The following pages have invalid frontmatter:

              #{failed_pages.map { |path, error| "#{path}: #{error}" }.join("\n")}

              All pages must have frontmatter with an explicit permalink.
              Add frontmatter at the top of the file like this:

              ---
              permalink: /your/path/
              ---
            MESSAGE
          end

          puts "All pages have valid frontmatter with permalinks!"
        end

        desc "Perform validations of the website, including doc tests and doc coverage"
        task validate: [:build, :validate_no_empty_code_snippets, :docs_coverage, :doctest, :validate_page_frontmatter, :validate_html_output]

        task build_css: :npm_install do
          require "rouge"
          require_relative "support/syntax_theme"

          ::Dir.chdir(SITE_SOURCE_DIR) do
            sh "npm run build:css"
            ::File.write("assets/css/highlight.css", ::ElasticGraph::SyntaxTheme.new.render)
          end
        end

        # When we are releasing gems, these dependencies aren't available.
        unless ENV["BUNDLE_GEMFILE"].to_s.end_with?("config/release/Gemfile")
          require "elastic_graph/local/rake_tasks"
          require "elastic_graph/query_registry/rake_tasks"

          namespace :examples do
            desc "Generate and extract code snippets from example schemas"
            task extract_snippets: EXAMPLE_SCHEMA_FILES_BY_NAME.keys.map { |schema| "#{schema}:extract_snippets" }

            EXAMPLE_SCHEMA_FILES_BY_NAME.each do |schema_name, schema_file|
              example_dir = schema_file.parent
              settings_file = example_dir / "local_settings.yaml"
              queries_dir = example_dir / "queries"

              namespace schema_name do
                ::ElasticGraph::Local::RakeTasks.new(local_config_yaml: settings_file, path_to_schema: schema_file) do |tasks|
                  tasks.opensearch_versions = []
                  tasks.enforce_json_schema_version = false
                end

                task validate: ["schema_artifacts:dump"] do
                  validation_file = ::File.join(example_dir, "validate.rb")
                  if ::File.exist?(validation_file)
                    sh "bundle exec ruby #{validation_file}"
                  end
                end

                task extract_snippets: :validate do
                  files = extract_snippets_from_dir(example_dir) do |file|
                    ::File.read(file).strip
                  end

                  snippets = extract_snippets_from_dir(example_dir) do |file|
                    extract_fenced_snippets_from_file(file)
                  end

                  data = {"files" => files, "snippets" => snippets}

                  ::FileUtils.mkdir_p JEKYLL_DATA_DIR
                  ::File.write(::File.join(JEKYLL_DATA_DIR, "#{schema_name}.yaml"), ::YAML.dump(data))
                end

                if queries_dir.exist?
                  ::ElasticGraph::QueryRegistry::RakeTasks.from_yaml_file(settings_file, queries_dir)
                  task "query_registry:validate_queries" => ["schema_artifacts:dump", "query_registry:dump_variables:all"]

                  task extract_snippets: "query_registry:validate_queries" do
                    queries_by_name_by_category = queries_dir.children.to_h do |category_path|
                      queries_by_name = category_path.glob("*.graphql").to_h do |query_path|
                        [query_path.basename.sub_ext("").to_s, query_path.read.strip]
                      end

                      [category_path.basename.to_s, queries_by_name]
                    end

                    ::FileUtils.mkdir_p JEKYLL_DATA_DIR
                    ::File.write(::File.join(JEKYLL_DATA_DIR, "#{schema_name}_queries.yaml"), ::YAML.dump(queries_by_name_by_category))
                  end
                end
              end
            end
          end
        end
      end
    end

    def extract_snippets_from_dir(dir, &block)
      Dir.children(dir).filter_map do |child|
        absolute_child = ::File.join(dir, child)

        child_snippets =
          if ::File.directory?(absolute_child)
            extract_snippets_from_dir(absolute_child, &block)
          else
            block.call(absolute_child)
          end

        [child.tr(".", "_"), child_snippets] unless child_snippets.empty?
      end.to_h
    end

    def extract_fenced_snippets_from_file(file)
      snippets = {}
      current_snippet_name = nil
      buffer = []

      File.readlines(file).each do |line|
        if line =~ /:snippet-start:\s*(\S+)/
          # start a new snippet
          current_snippet_name = $1
          buffer = []
        elsif /:snippet-end:/.match?(line)
          # end the current snippet
          snippets[current_snippet_name] = buffer.join.chomp
          current_snippet_name = nil
        elsif current_snippet_name
          # within a snippet
          buffer << line
        end
      end

      snippets
    end

    def watch_files(description, *args, **kwargs)
      ::Thread.new do
        ::Filewatcher.new(*args, **kwargs).watch do |changes|
          changed_files = changes.map do |file, _|
            ::Pathname.new(file).relative_path_from(REPO_ROOT)
          end.sort

          changed_file_descriptions = changes.map do |file, event|
            relative_path = ::Pathname.new(file).relative_path_from(REPO_ROOT)
            "#{relative_path} (#{event})"
          end.sort

          unless changed_files.empty?
            details =
              if changed_file_descriptions.size < 8
                changed_file_descriptions.join(", ")
              else
                "#{changed_file_descriptions.first(8).join(", ")}..."
              end

            puts "#{changed_file_descriptions.size} files changed (#{details}). #{description}..."
            yield changed_files
          end
        end
      end
    end

    # Yard doesn't allow us to suppress warnings. Warnings are for code constructs its not able to understand, and sometimes we're ok
    # with that (e.g. when the alternative is making the code worse or more verbose). Here we suppress warnings using custom logic:
    # we filter out specific warnings that we don't want to be notified about.
    YARD_WARNINGS_TO_IGNORE = {
      # `Data.define` metaprograms a superclass and there's not a way to avoid the warning:
      # https://github.com/lsegal/yard/issues/1533
      # https://github.com/lsegal/yard/issues/1477#issuecomment-1399339983
      "`Data.define` superclass" =>
        # https://rubular.com/r/lecYmbp981T4LY
        /^\[warn\]: in YARD::Handlers::Ruby::ClassHandler: Undocumentable superclass \(class was added without superclass\)\n\s+in file[^\n]+\n\n\s+\d+:[^\n]*?(Data\.define|Struct.new)[^\n]*\n\n/m,

      # We sometimes include/extend/prepend a mixin that is a dynamic module
      # (e.g. `include Mixins::HasReadableToSAndInspect.new`) and YARD isn't able to understand this.
      # That's fine, and we don't want a warning for this.
      "Undocumentable mixin" =>
        # https://rubular.com/r/o0Daj0rKgNLes0
        /^\[warn\]: in YARD::Handlers::Ruby::(Extend|Mixin)Handler: Undocumentable mixin: YARD::Parser::UndocumentableError[^\n]*\n\s+in file[^\n]+\n\n\s+\d+: (include|extend|prepend) [A-Za-z:]+\.new[^\n]*\n\n/m
    }

    def run_yard_doc_ignoring_expected_warnings
      command = yard_cmd("doc")
      puts "#{command}\n\n"

      t1 = ::Time.now
      doc_output = IO.popen(command).read
      t2 = ::Time.now

      ignored_warnings_output = YARD_WARNINGS_TO_IGNORE.filter_map do |warning, regex|
        if (count = doc_output.scan(regex).count) > 0
          "Ignored #{count} #{warning} warning(s)."
        end
      end.join("\n")

      filtered_output = YARD_WARNINGS_TO_IGNORE.values.reduce(doc_output) { |accum, regex| accum.gsub(regex, "") }

      <<~EOS.strip.tap { |output| puts output }
        YARD doc generation took #{(t2 - t1).round(3)} seconds.
        #{ignored_warnings_output}

        #{filtered_output}
      EOS
    end

    yardopts_from_file = ::File.read(::File.expand_path("yardopts", __dir__))
      .split("\n")
      .map(&:strip)
      .reject(&:empty?)

    YARD_DOC_OPTS = [
      "--output-dir #{YARD_OUTPUT_DIR}",
      "--db #{SITE_CONFIG_DIR}/.yardoc",
      *yardopts_from_file,
      *DOCUMENTED_GEMS
    ].join(" ")

    def yard_cmd(subcmd)
      "bundle exec yard #{subcmd} #{YARD_DOC_OPTS}"
    end

    COMMON_JEKYLL_ARGS = [
      "--source #{SITE_SOURCE_DIR}",
      "--destination #{JEKYLL_SITE_DIR}",
      "--baseUrl /elasticgraph",
      "--strict-front-matter",
      "--trace"
    ].join(" ")

    def run_jekyll(subcmd)
      sh "bundle exec jekyll #{subcmd} #{COMMON_JEKYLL_ARGS}"
    end
  end
end

ElasticGraph::SiteRakeTasks.new
